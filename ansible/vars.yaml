 # versions
kube_version: "v1.29.5"
java_version: "8"
helm_version: "3.15.1"
spark_operator_version: "2.0.2"
mongo_db_chart_version: "15.6.14"
kube_prometheus_stack_version: "66.3.0"
chaos_mesh_chart_version: "2.7.0"
# HiBench/Spark related versions (No official support in HiBench after Spark#3.1.* and Hadoop 3.2.4 as of november 2024)
hdfs_version: "3.3.4"
spark_version: "3.5.3"
spark_image: "apache/spark:{{ spark_version }}"
scala_version: "2.12.20"
hadoop_version: "3.3.6"
hibench_version: "827c9f6"
spark_hibench_profile: "3.5"
scala_hibench_profile: "2.12"

# general
listener_jar: "listener-assembly-0.1.0-SNAPSHOT.jar"

# this user can be used for ansible scripts and experiment execution
linux_username: "mtuser"
linux_password: "Admin1!"
hdfs_group: "hdfs"

# Kubernetes
k8s_namespace: "default"
k8s_monitoring_namespace: "monitoring"
k8s_chaos_mesh_namespace: "chaos-mesh"
storage_class: "local-storage"

# Chaos Mesh
termination_window: "*/5 * * * *" # Cron expression, termination every 5 minutes

# Grafana
grafana_admin_user: "admin"
grafana_admin_password: "password"

# MongoDB
replica_count: 1
replica_set_name: "rs0"
mongodb_database: "test"
mongodb_username: "test"
mongodb_root_username: "root"
mongodb_password: "Password1!"
mongodb_resource_preset: "small"

# HDFS
hadoop_master: "{{ hostvars['leaderNode']['ip'] }}"
hdfs_address: "hdfs://{{ hadoop_master }}:9000"
hdfs_replication_factor: 1

# local paths
working_dir: "{{ lookup('env', 'PWD') }}"
ansible_dir: "{{ working_dir }}/ansible"
local_template_dir: "{{ ansible_dir }}/templates"
hibench_template_dir: "{{ local_template_dir }}/hibench"
hadoop_template_dir: "{{ local_template_dir }}/hadoop"
local_patch_dir: "{{ ansible_dir }}/patch"

# remote paths
user_dir: "/home/{{ linux_username }}"
venv_path: "{{ user_dir }}/venv"
remote_template_dir: "{{ user_dir }}/templates"
hadoop_dir: "{{ user_dir }}/hadoop"
hibench_dir: "{{ user_dir }}/hibench"
archives_dir: "{{ user_dir }}/archives"
hdfs_user_dir: "/user/{{ linux_username }}"
