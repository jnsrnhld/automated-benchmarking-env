---
- name: Run HiBench benchmarks
  hosts: leader
  vars_files:
    - ../vars.yaml
    - ../benchmark-definition.yaml
  become: true
  become_user: "{{ linux_username }}"
  tasks:
    # TODO remove after fixing, already present in setup
    - name: Copy the JAR file to remote machine
      synchronize:
        src: "{{ lookup('env', 'PWD') }}/ansible/jars/{{ listener_jar }}"
        dest: "/tmp/{{ listener_jar }}"
        delete: yes

    - name: Copy jar to user dir
      command: "{{ hadoop_dir }}/bin/hdfs dfs -put -f /tmp/{{ listener_jar }} {{ hdfs_user_dir }}"

    - name: Template Hadoop config
      template:
        src: "{{ hibench_template_dir }}/hadoop.conf"
        dest: "{{ hibench_dir }}/conf/hadoop.conf"

    - name: Template HiBench config
      vars:
        parallelism: "{{ groups['follower'] | length }}"
      template:
        src: "{{ hibench_template_dir }}/hibench.conf"
        dest: "{{ remote_template_dir }}/hibench.conf"

    - name: Replace default hibench.conf
      copy:
        src: "{{ remote_template_dir }}/hibench.conf"
        dest: "{{ hibench_dir }}/conf/hibench.conf"
        remote_src: true

    - name: Template Spark config
      template:
        src: "{{ hibench_template_dir }}/spark.conf"
        dest: "{{ hibench_dir }}/conf/spark.conf"

    - name: Delete existing ConfigMap
      vars:
        ansible_python_interpreter: "{{ venv_path }}/bin/python3"
      kubernetes.core.k8s:
        kind: ConfigMap
        name: hibench-config
        namespace: "{{ k8s_namespace }}"
        state: absent

    - name: Deploy HiBench config as ConfigMap
      command: 'kubectl create configmap hibench-config --from-file="{{hibench_dir }}/conf/hibench.conf"'

    - name: Prepare templater dict
      vars:
        hibench_jar: "{{ hdfs_address }}{{ hdfs_user_dir }}/sparkbench-assembly-8.0-SNAPSHOT-dist.jar"
        lister_jar_full_path: "{{ hdfs_address }}{{ hdfs_user_dir }}/{{ listener_jar }}"
      copy:
        dest: "{{ hibench_dir }}/values.yaml"
        content: |
          spark_image: {{ spark_image }}
          hibench_jar: {{ hibench_jar }}
          # listener conf
          listener_jar: {{ lister_jar_full_path }}
          is_adaptive: {{ is_adaptive }}
          # app spec
          bridge_service_address: {{ bridge_service_address }}
          target_runtime: {{ target_runtime }}
          min_executors: {{ min_executors }}
          max_executors: {{ max_executors }}
          # driver spec
          driver_cores: {{ driver_cores }}
          driver_memory: {{ driver_memory }}
          # executor spec
          executor_cores: {{ executor_cores }}
          executor_memory: {{ executor_memory }}
          # environment spec
          hadoop_version: {{ hadoop_version }}
          spark_version: {{ spark_version }}
          scala_version: {{ scala_version }}
          java_version: {{ java_version }}

    - name: Run prepare script
      become_user: "{{ linux_username }}"
      command: bash "{{ hibench_dir }}/bin/workloads/{{ item.category }}/{{ item.name }}/prepare/prepare.sh"
      loop: "{{ workloads }}"
      when: item.enabled and not {{ skip_data_generation }}

    - name: Run benchmark
      become_user: "{{ linux_username }}"
      command: bash "{{ hibench_dir }}/bin/workloads/{{ item.1.category }}/{{ item.1.name }}/spark/run.sh"
      loop: "{{ range(0, runs) | product(workloads) | list }}"
      when: item.1.enabled
