---
- name: Prepare HiBench benchmark jobs
  hosts: leader
  become: true
  vars_files:
    - ../vars.yaml
    - ../benchmark-definition.yaml
  tasks:
    - name: Template Hadoop config
      template:
        src: "{{ hibench_template_dir }}/hadoop.conf"
        dest: "{{ hibench_dir }}/conf/hadoop.conf"

    - name: Template HiBench config
      template:
        src: "{{ hibench_template_dir }}/hibench.conf"
        dest: "{{ remote_template_dir }}/hibench.conf"

    - name: Replace default hibench.conf
      copy:
        src: "{{ remote_template_dir }}/hibench.conf"
        dest: "{{ hibench_dir }}/conf/hibench.conf"
        remote_src: yes

    - name: Template Spark config
      template:
        src: "{{ hibench_template_dir }}/spark.conf"
        dest: "{{ hibench_dir }}/conf/spark.conf"

    # generated workloads are automatically submitted to HDFS - if the script is stuck here, the machine likely has
    # not enough resources
    - name: Run prepare script
      become_user: "{{ linux_username }}"
      command: bash "{{ hibench_dir }}/bin/workloads/{{ item.path }}/prepare/prepare.sh"
      loop: "{{ workloads }}"
      when: item.enabled

    - name: Prepare templater dict
      vars:
        hibench_jar: "FIXME"
      copy:
        dest: "{{ hibench_dir }}/values.yaml"
        content: |
          spark_version: {{ spark_version }}
          hibench_jar: {{ hibench_jar }}
          listener_jar: {{ listener_jar }}
          hdfs_address: {{ hdfs_address }}

    - name: Run templater
      command:
        cmd: |
          bash generate_templates.sh \
            "{{ hibench_dir }}/bin/workloads/{{ item.value.path }}/run_command.sh" \
            "{{ hibench_dir }}/values.yaml" \
            "{{ hibench_dir }}/hibench-spark-app.yaml"
        chdir: "{{ hibench_dir }}"
      loop: "{{ workloads | dict2items }}"
      when: item.enabled
