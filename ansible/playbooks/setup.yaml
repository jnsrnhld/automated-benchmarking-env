---
- name: Setup user on remote machines
  hosts: remote
  vars_files:
    - ../vars.yaml
  become: true
  tasks:
    - name: Create a new user
      user:
        name: "{{ linux_username }}"
        password: "{{ linux_password | password_hash('sha512') }}"
        shell: /bin/bash
        state: present
        create_home: yes
        groups:
          - sudo
        append: yes

    - name: Allow new user to have passwordless sudo
      lineinfile:
        dest: /etc/sudoers
        state: present
        regexp: '^%{{ linux_username }}'
        line: '%{{ linux_username }} ALL=(ALL) NOPASSWD: ALL'
        validate: 'visudo -cf %s'

    - name: Install acl to fix a tmp-file creation issue when running ansible tasks as non-root user
      apt:
        name: acl
        state: present

    - name:
      file:
        path: "{{ remote_template_dir }}"
        state: directory
        mode: '0755'
        owner: "{{ linux_username }}"
        group: "{{ linux_username }}"

- name: Install Ansible/pip dependencies on leader machine
  hosts: leader
  vars_files:
    - ../vars.yaml
  become: true
  tasks:
    - name: Check if pip is installed
      command: python3 -m pip -V
      register: pip_installed
      ignore_errors: true

    - name: Download pip installer
      get_url:
        url: https://bootstrap.pypa.io/get-pip.py
        dest: /tmp/get-pip.py
        mode: '0644'
      when: pip_installed.failed

    - name: Run pip installer
      command: python3 /tmp/get-pip.py --user
      when: pip_installed.failed

    - name: Ensure python3-venv is installed
      apt:
        name: python3-venv
        state: present
        force_apt_get: true
        update_cache: true

    - name: Install pip packages
      pip:
        name:
          - packaging
          - virtualenv
          - jinja2
          - pathlib

    - name: Create virtual environment
      become_user: root
      command:
        cmd: python3 -m venv {{ venv_path }}
        creates: "{{ venv_path }}"

    - name: Install pre-requisites
      pip:
        name:
          - openshift
          - pyyaml
          - kubernetes
        virtualenv: "{{ venv_path }}"
        virtualenv_site_packages: true

- name: Check kubectl is present on leader node
  hosts: leader
  vars_files:
    - ../vars.yaml
  become: true
  tasks:
    - name: Check if kubectl is installed and connected to cluster
      command: kubectl cluster-info
      register: kubectl_installed
      ignore_errors: true

    - name: Fail playbook
      fail:
        msg: kubectl not installed or not connected with a cluster on leader node. Can't continue playbook without a present k8s deployment.
      when: kubectl_installed.rc != 0

    - name: Ensure .kube directory exists for user {{ linux_username }}
      file:
        path: /home/{{ linux_username }}/.kube
        state: directory
        owner: "{{ linux_username }}"
        group: "{{ linux_username }}"
        mode: '0755'

    - name: Copy kubeconfig to {{ linux_username }}'s home directory
      copy:
        remote_src: true
        src: /etc/kubernetes/admin.conf
        dest: "{{ user_dir}}/.kube/config"
        owner: "{{ linux_username }}"
        group: "{{ linux_username }}"
        mode: '0644'

- name: Install helm on leader node
  hosts: leader
  vars_files:
    - ../vars.yaml
  tasks:
    - name: Check if helm is installed
      command: which helm
      register: helm_installed
      ignore_errors: true

    - name: Download Helm installation script
      get_url:
        url: https://raw.githubusercontent.com/helm/helm/master/scripts/get
        dest: /tmp/get_helm.sh
        mode: '0755'
      when: helm_installed.failed
      become: true

    - name: Install Helm
      command: /tmp/get_helm.sh -v "v{{ helm_version }}"
      when: helm_installed.failed
      become: true

    - name: Remove Helm installation script
      file:
        path: /tmp/get_helm.sh
        state: absent
      when: helm_installed.failed
      become: true

- name: Deploy spark-operator helm chart
  hosts: leader
  vars_files:
    - ../vars.yaml
  become: true
  tasks:
    - name: Add spark-operator repository
      kubernetes.core.helm_repository:
        name: spark-operator
        repo_url: https://kubeflow.github.io/spark-operator

    - name: Deploy spark-operator helm chart
      kubernetes.core.helm:
        name: spark-operator
        chart_ref: spark-operator/spark-operator
        chart_version: "{{ spark_operator_version }}"
        release_namespace: "{{ k8s_namespace }}"
        atomic: true
        wait: true

- name: Deploy MongoDB replica set
  hosts: leader
  vars_files:
    - ../vars.yaml
  become: true
  tasks:
    # to be on the save side and prevent any manual managing effort,
    # we'll create more persistent volumes than actually required
    - name: Create MongoDB directory
      file:
        path: "/mnt/disks/mongodb-data-{{ ansible_hostname | lower }}"
        state: directory
        mode: '0755'
      loop: "{{ range(1, replica_count + 1) }}"

    - name: Create MongoDB target directory if it does not exist
      file:
        path: "{{ user_dir }}/mongodb-data-{{ ansible_hostname | lower }}"
        state: directory
        mode: '0755'
        owner: "{{ linux_username }}"
        group: "{{ linux_username }}"
      loop: "{{ range(1, replica_count + 1) }}"

    - name: Bind mount MongoDB directories
      ansible.posix.mount:
        src: "{{ user_dir }}/mongodb-data-{{ ansible_hostname | lower }}"
        path: "/mnt/disks/mongodb-data-{{ ansible_hostname | lower }}"
        fstype: none
        opts: bind
        state: mounted
      loop: "{{ range(1, replica_count + 1) }}"

    - name: Deploy mongodb helm chart
      kubernetes.core.helm:
        name: mongodb
        chart_ref: oci://registry-1.docker.io/bitnamicharts/mongodb
        chart_version: "{{ mongo_db_chart_version }}"
        release_namespace: "{{ k8s_namespace }}"
        atomic: true
        wait: true
        values:
          architecture: replicaset
          replicaSetName: "{{ replica_set_name }}"
          persistence:
            storageClass: "{{ storage_class }}"
          replicaCount: "{{ replica_count }}"
          auth:
            rootUser: "{{ mongodb_root_username }}"
            usernames:
              - "{{ mongodb_username }}"
            passwords:
              - "{{ mongodb_password }}"
            databases:
              - "{{ mongodb_database }}"
          arbiter:
            resourcesPreset: "{{ mongodb_resource_preset }}"

- name: Deploy Hadoop
  hosts: remote
  vars_files:
    - ../vars.yaml
  become: true
  tasks:
    - name: Setup dependencies
      block:
        - name: Install apt dependencies
          apt:
            pkg:
              - ssh
              - pdsh
              - bc
              - python2
              - openjdk-{{ java_version }}-jdk
              - maven
            state: present

        - name: Verify Python2 installation
          command: which python2
          register: python_check
          failed_when: python_check.rc != 0

        - name: Verify Java installation
          command: which java
          register: java_check
          failed_when: java_check.rc != 0

        - name: Verify Maven installation
          command: which mvn
          register: maven_check
          failed_when: maven_check.rc != 0

        - name: Set main Java version to {{ java_version }}
          shell: update-alternatives --set java /usr/lib/jvm/java-{{ java_version }}-openjdk-amd64/jre/bin/java

        - name: Add JAVA_HOME to .bashrc
          lineinfile:
            path: "{{ user_dir }}/.bashrc"
            line: 'export JAVA_HOME=$(readlink -f $(which java) | sed "s:bin/java::")'
            state: present

        - name: Add JAVA_HOME to PATH in .bashrc
          lineinfile:
            path: "{{ user_dir }}/.bashrc"
            line: 'export PATH=$JAVA_HOME/bin:$PATH'
            state: present

        - name: Ensure .ssh dir is present
          file:
            path: "{{ user_dir }}/.ssh"
            state: directory
            mode: '0755'
            owner: "{{ linux_username }}"
            group: "{{ linux_username }}"

        - name: Generate an SSH key pair if it doesn't exist
          openssh_keypair:
            path: "{{ user_dir }}/.ssh/id_rsa"
            type: rsa
            passphrase: ''
            comment: 'generated by ansible'
            owner: "{{ linux_username }}"
          register: ssh_key

        - name: Ensure the public key is in the authorized_keys file
          lineinfile:
            path: "{{ user_dir }}/.ssh/authorized_keys"
            line: "{{ ssh_key.public_key }}"
            create: yes
            mode: '0600'

        - name: Ensure correct permissions for authorized_keys
          file:
            path: "{{ user_dir }}/.ssh/authorized_keys"
            mode: '0600'
            owner: "{{ linux_username }}"
            group: "{{ linux_username }}"

        - name: Create hdfs user group
          group:
            name: hdfs
            state: present

        - name: Add user to hdfs group
          user:
            name: "{{ linux_username }}"
            groups: hdfs
            append: yes

    - name: Setup Hadoop
      become_user: "{{ linux_username }}"
      block:
        - name: Download Hadoop tarball
          get_url:
            url: "https://dlcdn.apache.org/hadoop/common/hadoop-{{ hadoop_version }}/hadoop-{{ hadoop_version }}.tar.gz"
            dest: /tmp/hadoop.tar.gz

        - name: Create Hadoop installation directory
          file:
            path: "{{ hadoop_dir }}"
            state: directory
            mode: '0755'
            owner: "{{ linux_username }}"
            group: "{{ linux_username }}"
            recurse: yes

        - name: Extract Hadoop tarball
          unarchive:
            src: /tmp/hadoop.tar.gz
            dest: "{{ hadoop_dir }}"
            remote_src: yes
            extra_opts: [ --strip-components=1 ]
            # this could be any file nested in hadoop_dir which is created after extracting successfully
            creates: "{{ hadoop_dir }}/etc/hadoop/hadoop-env.sh"

        - name: Set JAVA_HOME in hadoop-env.sh
          lineinfile:
            path: "{{ hadoop_dir }}/etc/hadoop/hadoop-env.sh"
            regexp: '^export JAVA_HOME='
            line: 'export JAVA_HOME=$(readlink -f $(which java) | sed "s:bin/java::")'
            state: present

        - name: Template *-site.xml files
          template:
            src: "{{ hadoop_template_dir }}/{{ item }}"
            dest: "{{ hadoop_dir }}/etc/hadoop/{{ item }}"
          vars:
            leader_hostname: "{{ hostvars['leaderNode']['ansible_hostname'] }}"
          loop:
            - core-site.xml
            - hdfs-site.xml
            - mapred-site.xml
            - yarn-site.xml

        - name: Ensure hadoop logs directory has correct permissions
          file:
            path: "{{ hadoop_dir }}/logs"
            owner: "{{ linux_username }}"
            group: "{{ linux_username }}"
            mode: '0755'
            state: directory

- name: Start HDFS namenode/resourcemanager
  hosts: leader
  vars_files:
    - ../vars.yaml
  become: true
  become_user: "{{ linux_username }}"
  tasks:
    - name:
      shell:
        cmd: | 
          # ansible is not sourcing .bashrc
          export JAVA_HOME=$(readlink -f $(which java) | sed "s:bin/java::")
          export PATH=$JAVA_HOME/bin:$PATH
          export PDSH_RCMD_TYPE=ssh
  
          # stopping services
          bin/hdfs --daemon stop namenode
          bin/yarn --daemon stop resourcemanager
          sudo rm -rf /tmp/hadoop-{{ linux_username }}/*
  
          # starting services
          bin/hdfs namenode -format
          bin/hdfs --daemon start namenode
          bin/yarn --daemon start resourcemanager
        chdir: "{{ hadoop_dir }}"

    - name: Run jps and capture the output
      command: jps
      register: jps_output

    - name: Verify that all required JVM processes are running
      assert:
        that:
          - "'NameNode' in jps_output.stdout"
          - "'ResourceManager' in jps_output.stdout"
        fail_msg: "One or more required JVM processes are not running. Output was {{ jps_output.stdout }}"
        success_msg: "All required JVM processes are running"

- name: Start HDFS datanode/nodemanager
  hosts: follower
  vars_files:
    - ../vars.yaml
  become: true
  become_user: "{{ linux_username }}"
  tasks:
    - name:
      shell:
        cmd: |
          # ansible is not sourcing .bashrc
          export JAVA_HOME=$(readlink -f $(which java) | sed "s:bin/java::")
          export PATH=$JAVA_HOME/bin:$PATH
          export PDSH_RCMD_TYPE=ssh
  
          # stopping services
          bin/hdfs --daemon stop datanode
          bin/yarn --daemon stop nodemanager
          sudo rm -rf /tmp/hadoop-{{ linux_username }}/*
  
          # starting services
          bin/hdfs namenode -format
          bin/hdfs --daemon start datanode
          bin/yarn --daemon start nodemanager
        chdir: "{{ hadoop_dir }}"

    - name: Run jps and capture the output
      command: jps
      register: jps_output

    - name: Verify that all required JVM processes are running
      assert:
        that:
          - "'DataNode' in jps_output.stdout"
          - "'NodeManager' in jps_output.stdout"
        fail_msg: "One or more required JVM processes are not running. Output was {{ jps_output.stdout }}"
        success_msg: "All required JVM processes are running"

- name: Copy custom SparkListener to HDFS
  hosts: leader
  vars_files:
    - ../vars.yaml
  become: true
  become_user: "{{ linux_username }}"
  tasks:
    - name: Copy the JAR file to remote machine
      synchronize:
        src: "{{ lookup('env', 'PWD') }}/ansible/jars/{{ listener_jar }}"
        dest: "/tmp/{{ listener_jar }}"
        delete: yes

    - name: Create user dir in hdfs
      command: "{{ hadoop_dir }}/bin/hdfs dfs -mkdir -p {{ hdfs_user_dir }}"

    - name: Copy jar to user dir
      command: "{{ hadoop_dir }}/bin/hdfs dfs -put -f /tmp/{{ listener_jar }} {{ hdfs_user_dir }}"

- name: Deploy HiBench
  hosts: leader
  vars_files:
    - ../vars.yaml
  become: true
  become_user: "{{ linux_username }}"
  tasks:
    - name: Provide cached archives to speed up HiBench build
      block:
        - name: Ensure archives dir exists
          file:
            path: "{{ archives_dir }}"
            state: directory
            owner: "{{ linux_username }}"
            group: "{{ linux_username }}"
            mode: '0755'

        - name: Add maven archives to cache
          synchronize:
            src: "{{ lookup('env', 'PWD') }}/.m2.repository.cache.maven-download-plugin"
            dest: "{{ archives_dir }}"
            recursive: true

        - name: Template adjusted pom.xml files
          template:
            src: "{{hibench_template_dir}}/{{ item.template }}"
            dest: "{{ hibench_dir}}/{{ item.path }}"
          loop:
            - { path: "hadoopbench/mahout/pom.xml", template: "mahout.pom.xml" }
            - { path: "hadoopbench/sql/pom.xml", template: "sql.pom.xml" }
            - { path: "hadoopbench/nutchindexing/pom.xml", template: "nutch.pom.xml" }

    - name: Create directory for HiBench
      file:
        path: "{{ hibench_dir }}"
        state: directory
        mode: '0755'
        owner: "{{ linux_username }}"
        group: "{{ linux_username }}"
        recurse: yes

    - name: Pull HiBench repository
      become_user: "{{ linux_username }}" # otherwise we get ownership issues
      git:
        repo: https://github.com/Intel-bigdata/HiBench.git
        dest: "{{ hibench_dir }}"
        version: "{{ hibench_version }}"
        force: yes
        update: yes

    - name: Build HiBench
      shell:
        cmd: "mvn -Psparkbench -Dspark={{ spark_hibench_profile }} -Dscala={{ scala_hibench_profile }} clean package"
        chdir: "{{ hibench_dir }}"

    - name: Copy SparApp template
      copy:
        src: "{{ local_template_dir }}/hibench-spark-app.yaml"
        dest: "{{ hibench_dir }}"
        owner: "{{ linux_username }}"
        group: "{{ linux_username }}"
        mode: '0644'

    - name: Copy scripts to HiBench dir
      copy:
        src: "{{ local_scripts_dir }}/{{ item }}"
        dest: "{{ hibench_dir }}"
        owner: "{{ linux_username }}"
        group: "{{ linux_username }}"
        mode: '0644'
      loop:
        - generate_templates.sh
        - run_script_modifier.py
        - sparkapp-templater.py

    - name: Execute run_script_modifier.py
      vars:
        ansible_python_interpreter: "{{ venv_path }}/bin/python3"
      command:
        cmd: "python3 run_script_modifier.py {{ hibench_dir }}"
        chdir: "{{ hibench_dir }}"
