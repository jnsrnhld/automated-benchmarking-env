# Data scale profile. Available value is tiny, small, large, huge, gigantic and bigdata.
# The definition of these profiles can be found in the workload's conf file,
# i.e. https://github.com/Intel-bigdata/HiBench/blob/master/conf/workloads/micro/wordcount.conf
scale: tiny # {tiny, small, large, huge, gigantic, bigdata}

# Which workloads do you want to run?
workloads:
  # MICRO
  - { name: "repartition", enabled: false, category: "micro" }
  - { name: "sleep", enabled: false, category: "micro" }
  - { name: "sort", enabled: false, category: "micro" }
  - { name: "terasort", enabled: false, category: "micro" }
  - { name: "wordcount", enabled: false, category: "micro" }
  # MACHINE LEARNING
  - { name: "als", enabled: true, category: "ml" }
  - { name: "bayes", enabled: false, category: "ml" }
  - { name: "kmeans", enabled: false, category: "ml" }
